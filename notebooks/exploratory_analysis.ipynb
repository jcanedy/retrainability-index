{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "57a14d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b0629777",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pl.read_parquet(\"../data/processed/wioa_data_tier2.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f7d6277a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for modeling (encode categorical variables)\n",
    "tier2_data = data.filter(pl.col(\"outcome_tier\") == \"Tier 2\").to_pandas()\n",
    "tier2_data = data.filter(pl.col(\"outcome_tier\") == \"Tier 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee04a868",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensions = [\n",
    "    'low_income_x', 'employment_status_x', 'received_training_x',\n",
    "    'race_ethnicity_x', 'sex_x', 'age_x', 'highest_education_level_x',\n",
    "    'training_service_type_1_x', 'industry_title_x'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9eb765d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variables\n",
    "encoders = {}\n",
    "X = tier2_data[dimensions].copy()\n",
    "for col in dimensions:\n",
    "    if X[col].dtype == 'object':\n",
    "        encoders[col] = LabelEncoder()\n",
    "        X[col] = encoders[col].fit_transform(X[col].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb914d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each outcome variable, get feature importance\n",
    "outcomes = ['bin_r_cog_industry_y', 'bin_r_man_industry_y', 'bin_offshor_industry_y', 'bin_wages_mean_y']\n",
    "\n",
    "importance_scores = {}\n",
    "for outcome in outcomes:\n",
    "    y = tier2_data[outcome].dropna()\n",
    "    X_clean = X.loc[y.index]\n",
    "    \n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "    rf.fit(X_clean, y)\n",
    "    \n",
    "    importance_scores[outcome] = dict(zip(dimensions, rf.feature_importances_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33d27c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension importance rankings:\n",
      "industry_title_x: 0.5096\n",
      "highest_education_level_x: 0.1304\n",
      "race_ethnicity_x: 0.1076\n",
      "age_x: 0.0869\n",
      "employment_status_x: 0.0531\n",
      "sex_x: 0.0400\n",
      "training_service_type_1_x: 0.0292\n",
      "received_training_x: 0.0223\n",
      "low_income_x: 0.0209\n"
     ]
    }
   ],
   "source": [
    "# Average importance across all outcomes\n",
    "avg_importance = {dim: np.mean([importance_scores[outcome][dim] for outcome in outcomes]) \n",
    "                  for dim in dimensions}\n",
    "\n",
    "# Sort by importance\n",
    "sorted_dims = sorted(avg_importance.items(), key=lambda x: x[1], reverse=True)\n",
    "print(\"Dimension importance rankings:\")\n",
    "for dim, score in sorted_dims:\n",
    "    print(f\"{dim}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6a7a29b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highly correlated dimension pairs:\n",
      "received_training_x <-> training_service_type_1_x: 0.666\n"
     ]
    }
   ],
   "source": [
    "correlation_matrix = X.corr()\n",
    "high_corr_pairs = []\n",
    "\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i+1, len(correlation_matrix.columns)):\n",
    "        if abs(correlation_matrix.iloc[i, j]) > 0.5:  # threshold for high correlation\n",
    "            high_corr_pairs.append((correlation_matrix.columns[i], correlation_matrix.columns[j]))\n",
    "\n",
    "print(\"Highly correlated dimension pairs:\")\n",
    "for pair in high_corr_pairs:\n",
    "    print(f\"{pair[0]} <-> {pair[1]}: {correlation_matrix.loc[pair[0], pair[1]]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5bbfe2f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high_corr_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54680141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dimension significance rankings:\n",
      "low_income_x: 10.0000\n",
      "employment_status_x: 10.0000\n",
      "race_ethnicity_x: 10.0000\n",
      "sex_x: 10.0000\n",
      "age_x: 10.0000\n",
      "highest_education_level_x: 10.0000\n",
      "training_service_type_1_x: 10.0000\n",
      "industry_title_x: 10.0000\n",
      "received_training_x: 7.8154\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "import pandas as pd\n",
    "\n",
    "# Test association between each dimension and outcomes\n",
    "significance_scores = {}\n",
    "\n",
    "for dim in dimensions:\n",
    "    dim_scores = []\n",
    "    for outcome in outcomes:\n",
    "        # Create contingency table\n",
    "        contingency = pd.crosstab(tier2_data[dim], tier2_data[outcome])\n",
    "        \n",
    "        # Chi-square test\n",
    "        chi2, p_value, dof, expected = chi2_contingency(contingency)\n",
    "        \n",
    "        # Use negative log p-value as importance score (higher = more significant)\n",
    "        importance = -np.log10(p_value + 1e-10)  # Add small value to avoid log(0)\n",
    "        dim_scores.append(importance)\n",
    "    \n",
    "    significance_scores[dim] = np.mean(dim_scores)\n",
    "\n",
    "# Sort by significance\n",
    "sorted_significance = sorted(significance_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "print(\"\\nDimension significance rankings:\")\n",
    "for dim, score in sorted_significance:\n",
    "    print(f\"{dim}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fba97ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "low_income_x: no consolidation needed (2 categories)\n",
      "employment_status_x: consolidated to 2 categories (from 3)\n",
      "received_training_x: no consolidation needed (2 categories)\n",
      "race_ethnicity_x: consolidated to 6 categories (from 7)\n",
      "sex_x: consolidated to 2 categories (from 3)\n",
      "age_x: consolidated to 6 categories (from 7)\n",
      "highest_education_level_x: consolidated to 8 categories (from 9)\n",
      "training_service_type_1_x: consolidated to 2 categories (from 3)\n",
      "industry_title_x: no consolidation needed (13 categories)\n",
      "\n",
      "Summary:\n",
      "Consolidated: 6 columns\n",
      "Unchanged: 3 columns\n"
     ]
    }
   ],
   "source": [
    "def consolidate_multiple_columns(data, columns, min_percentage=0.02):\n",
    "    \"\"\"Consolidate multiple columns at once, overwriting originals\"\"\"\n",
    "    \n",
    "    consolidated_data = data\n",
    "    consolidated_columns = []\n",
    "    non_consolidated_columns = []\n",
    "    \n",
    "    for column in columns:\n",
    "        # Skip if column is not string/categorical\n",
    "        if consolidated_data[column].dtype not in [pl.String, pl.Categorical]:\n",
    "            non_consolidated_columns.append(column)\n",
    "            print(f\"{column}: skipped (not categorical)\")\n",
    "            continue\n",
    "            \n",
    "        total_count = consolidated_data.height\n",
    "        value_counts = consolidated_data.select(pl.col(column).value_counts()).unnest(column)\n",
    "        \n",
    "        # Calculate percentages\n",
    "        value_counts = value_counts.with_columns(\n",
    "            (pl.col(\"count\") / total_count).alias(\"percentage\")\n",
    "        )\n",
    "        \n",
    "        # Keep categories above threshold\n",
    "        keep_categories = value_counts.filter(\n",
    "            pl.col(\"percentage\") >= min_percentage\n",
    "        ).select(column).to_series().to_list()\n",
    "        \n",
    "        original_categories = value_counts.height\n",
    "        kept_categories = len(keep_categories)\n",
    "        \n",
    "        # Only consolidate if we're actually reducing categories\n",
    "        if kept_categories < original_categories:\n",
    "            # Overwrite original column with consolidated version\n",
    "            consolidated_data = consolidated_data.with_columns(\n",
    "                pl.when(pl.col(column).is_in(keep_categories))\n",
    "                .then(pl.col(column))\n",
    "                .otherwise(pl.lit(\"Other\"))\n",
    "                .alias(column)  # Same name as original\n",
    "            )\n",
    "            consolidated_columns.append(column)\n",
    "            print(f\"{column}: consolidated to {kept_categories} categories (from {original_categories})\")\n",
    "        else:\n",
    "            # No consolidation needed\n",
    "            non_consolidated_columns.append(column)\n",
    "            print(f\"{column}: no consolidation needed ({original_categories} categories)\")\n",
    "    \n",
    "    return consolidated_data, consolidated_columns, non_consolidated_columns\n",
    "\n",
    "# Use it - much cleaner!\n",
    "tier2_data, consolidated_cols, non_consolidated_cols = consolidate_multiple_columns(\n",
    "    tier2_data, dimensions, min_percentage=0.02\n",
    ")\n",
    "\n",
    "print(f\"\\nSummary:\")\n",
    "print(f\"Consolidated: {len(consolidated_cols)} columns\")\n",
    "print(f\"Unchanged: {len(non_consolidated_cols)} columns\")\n",
    "\n",
    "# Use the same dimension names for rollup - no need to track different column names!\n",
    "grouping_sets = [list(c) for i in range(1, len(dimensions)+1) for c in combinations(dimensions, i)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1fbe66fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (12, 1)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>training_service_type_1_x</th></tr><tr><td>str</td></tr></thead><tbody><tr><td>&quot;Job Readiness Training in conj…</td></tr><tr><td>&quot;ABE or ESL (contextualized or …</td></tr><tr><td>&quot;Entrepreneurial Training (non-…</td></tr><tr><td>&quot;ABE or ESL (contextualized or …</td></tr><tr><td>&quot;On the Job Training (non-WIOA …</td></tr><tr><td>&hellip;</td></tr><tr><td>&quot;Customized Training&quot;</td></tr><tr><td>&quot;Prerequisite Training&quot;</td></tr><tr><td>&quot;Other Non-Occupational-Skills …</td></tr><tr><td>&quot;No Training Service&quot;</td></tr><tr><td>&quot;Occupational Skills Training (…</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (12, 1)\n",
       "┌─────────────────────────────────┐\n",
       "│ training_service_type_1_x       │\n",
       "│ ---                             │\n",
       "│ str                             │\n",
       "╞═════════════════════════════════╡\n",
       "│ Job Readiness Training in conj… │\n",
       "│ ABE or ESL (contextualized or … │\n",
       "│ Entrepreneurial Training (non-… │\n",
       "│ ABE or ESL (contextualized or … │\n",
       "│ On the Job Training (non-WIOA … │\n",
       "│ …                               │\n",
       "│ Customized Training             │\n",
       "│ Prerequisite Training           │\n",
       "│ Other Non-Occupational-Skills … │\n",
       "│ No Training Service             │\n",
       "│ Occupational Skills Training (… │\n",
       "└─────────────────────────────────┘"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tier2_data_consolidated.select(pl.col(\"training_service_type_1_x\")).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cc824308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 1)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>training_service_type_1_x_consolidated</th></tr><tr><td>str</td></tr></thead><tbody><tr><td>&quot;Occupational Skills Training (…</td></tr><tr><td>&quot;Other&quot;</td></tr><tr><td>&quot;No Training Service&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 1)\n",
       "┌─────────────────────────────────┐\n",
       "│ training_service_type_1_x_cons… │\n",
       "│ ---                             │\n",
       "│ str                             │\n",
       "╞═════════════════════════════════╡\n",
       "│ Occupational Skills Training (… │\n",
       "│ Other                           │\n",
       "│ No Training Service             │\n",
       "└─────────────────────────────────┘"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tier2_data_consolidated.select(pl.col(\"training_service_type_1_x_consolidated\")).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f687cf2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "retainability-index",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
